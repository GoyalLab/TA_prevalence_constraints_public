{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### looking at CRISPR KO gene length to determine if genes with upregulated paralogs are longer for Mellis et al. 2023\n",
    "### Created by Madeline E Melzer on 20230816, Last edit by Madeline E Melzer on 20231126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T16:36:25.480508Z",
     "start_time": "2023-08-16T16:36:25.192941Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T17:39:11.246927Z",
     "start_time": "2023-08-17T17:39:11.246298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grn_nitc_path = \"/Users/mem3579/Library/CloudStorage/OneDrive-NorthwesternUniversity/Arispe and Goyal Labs/transcriptionalCompensation/grn_nitc/\"\n",
    "\n",
    "fcDir = os.path.join(grn_nitc_path, \"rnaseq/de_analysis/p_fc/FC2/tabular_format/\")\n",
    "pctUpregDir = os.path.join(grn_nitc_path, \"rnaseq/de_analysis/p_fc/percent_upregulated/tabular_format/\")\n",
    "paralogDir = os.path.join(grn_nitc_path, \"rnaseq/paralog_data/\")\n",
    "orthologDir = os.path.join(grn_nitc_path, \"rnaseq/supp_analyses/orthologs/ortholog_data/\")\n",
    "outputDir = os.path.join(grn_nitc_path, \"rnaseq/supp_analyses/length/data/\")\n",
    "\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_42570/4224509336.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  paralogs = pd.concat([paralogs, data], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# combining data files for paralogs\n",
    "\n",
    "paralogFiles = [file for file in os.listdir(paralogDir) if file.endswith('.csv')]\n",
    "\n",
    "paralogs = pd.DataFrame()\n",
    "\n",
    "for file in paralogFiles:\n",
    "    file_path = os.path.join(paralogDir, file)\n",
    "    if os.path.getsize(file_path) == 0:\n",
    "        print(f\"Skipping empty file: {file}\")\n",
    "        continue\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['dataset'] = os.path.splitext(file)[0]\n",
    "\n",
    "    paralogs = pd.concat([paralogs, data], ignore_index=True)\n",
    "\n",
    "combined_file_path = os.path.join(outputDir, 'combinedParalogs.csv')\n",
    "#paralogs.to_csv(combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T18:05:59.835423Z",
     "start_time": "2023-08-17T18:05:59.771760Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combining data files for fc\n",
    "\n",
    "fcFiles = [file for file in os.listdir(fcDir) if file.endswith('.csv')]\n",
    "\n",
    "fcs = pd.DataFrame()\n",
    "\n",
    "for file in fcFiles:\n",
    "    file_path = os.path.join(fcDir, file)\n",
    "    if os.path.getsize(file_path) == 0:\n",
    "        print(f\"Skipping empty file: {file}\")\n",
    "        continue\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['dataset'] = os.path.splitext(file)[0]\n",
    "\n",
    "    fcs = pd.concat([fcs, data], ignore_index=True)\n",
    "\n",
    "# Rename the \"KO_Gene\" column to \"Gene\" to match combinedParalogs\n",
    "fcs.rename(columns={'KO_Gene': 'Gene'}, inplace=True)\n",
    "\n",
    "combined_file_path = os.path.join(outputDir, 'combinedfcs.csv')\n",
    "#fcs.to_csv(combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all files for percent upregulated\n",
    "\n",
    "pctUpregFiles = [file for file in os.listdir(pctUpregDir) if file.endswith('.csv')]\n",
    "\n",
    "pctUpregs = pd.DataFrame()\n",
    "\n",
    "for file in pctUpregFiles:\n",
    "    file_path = os.path.join(pctUpregDir, file)\n",
    "    if os.path.getsize(file_path) == 0:\n",
    "        print(f\"Skipping empty file: {file}\")\n",
    "        continue\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data[data['variable'] == 'Paralogs'] # Filter data to keep only rows where \"Variable\" is \"Paralogs\", not \"Bootstrapped Genes\"\n",
    "    data['dataset'] = os.path.splitext(file)[0]\n",
    "\n",
    "    pctUpregs = pd.concat([pctUpregs, data], ignore_index=True)\n",
    "\n",
    "# Rename the \"KO_Gene\" column to \"Gene\" to match other dataframes\n",
    "pctUpregs.rename(columns={'KO_Gene': 'Gene'}, inplace=True)\n",
    "\n",
    "combined_file_path = os.path.join(outputDir, 'combinedPctUpregs.csv')\n",
    "#pctUpregs.to_csv(combined_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T18:06:02.663412Z",
     "start_time": "2023-08-17T18:06:02.635301Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combining the paralog, fold change (fc), and pctUpreg .csv files\n",
    "\n",
    "# Load the combined CSV files\n",
    "paralogs = pd.read_csv(os.path.join(outputDir, 'combinedParalogs.csv'))\n",
    "fcs = pd.read_csv(os.path.join(outputDir, 'combinedfcs.csv'))\n",
    "pctUpregs = pd.read_csv(os.path.join(outputDir, 'combinedPctUpregs.csv'))\n",
    "\n",
    "# Create a subset of paralogs DataFrame\n",
    "paralogs_subset = paralogs[['Gene', 'Paralog', 'ko_length', 'paralog_length']] # dont need the dataset column from paralogs. \n",
    "\n",
    "# Perform a left join based on \"Gene\" and \"Paralog\" columns\n",
    "allData = pd.merge(fcs, paralogs_subset, how='left', on=['Gene', 'Paralog'])\n",
    "\n",
    "# Adding in p-value of expression comparison\n",
    "pctUpregs_subset = pctUpregs[['Gene', 'dataset', 'Percent Upregulated', 'p_value']] # Create a subset of pctUpregs DataFrame\n",
    "allData = pd.merge(allData, pctUpregs_subset, how='left', on=['Gene', 'dataset']) # Perform a left join based on \"Gene\" column\n",
    "allData.rename(columns={'p_value': 'pctUpreg_p_value'}, inplace=True) # Rename the 'P-value' column to 'pctUpreg_p_value' for expression comparison p-value\n",
    "allData.reset_index(drop=True, inplace=True) # Reset the index and drop it so it doesnt interfere with dropping duplicate rows\n",
    "allData.drop_duplicates(inplace=True) # Drop duplicate rows created by the join\n",
    "\n",
    "# Save the joined data to a new CSV file\n",
    "combined_file_path = os.path.join(outputDir, 'allData.csv')\n",
    "#allData.to_csv(combined_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique CRISPR gene targets:  73\n",
      "Unique CRISPR gene targets:  ['ASH1L' 'Actb' 'Actg1' 'Aff3' 'Apc' 'BUB1B' 'CMTR1' 'Cdk8' 'Csnk1a1'\n",
      " 'Etv5' 'FOSL1' 'Fbxw7' 'Fermt2' 'Furin' 'Hprt' 'IKZF5' 'INO80' 'JUNB'\n",
      " 'Jarid2' 'Jmjd1c' 'KDM1A' 'KLF6' 'KMT2A' 'L3mbtl3' 'LCK' 'Lmna' 'MBD2'\n",
      " 'MTF1' 'Macf1' 'Mbd3' 'Msi2' 'Myc' 'Myo10' 'NSD1' 'Nes' 'Nmt1' 'Nsd1'\n",
      " 'PLK1' 'POLK' 'PRPF4B' 'Pten' 'Pum1' 'RB1' 'REL' 'RUNX3' 'Raf1' 'RhoC'\n",
      " 'SIX6' 'SMARCA4' 'SMC3' 'SOX10' 'SP1' 'SRF' 'STAG2' 'STK11' 'Smg7' 'TFAM'\n",
      " 'TLR4' 'TP53' 'Tcf7l1' 'Tet1' 'Trim71' 'UBR5' 'Usp7' 'Usp9x' 'VEZF1'\n",
      " 'WDR7' 'ZEB2' 'Zfp281' 'Zfp423' 'p50' 'p52' 'p65']\n",
      "['ASH1L' 'Actb' 'Apc' 'KLF6' 'Lmna' 'Macf1' 'Myc' 'Nes' 'Nsd1' 'RB1'\n",
      " 'RUNX3' 'SP1' 'TLR4' 'Trim71' 'ZEB2' 'Zfp281']\n",
      "Number of unique genes passing DESeq2 Filters:  16\n",
      "Number of unique 'Gene-Paralog' pairs:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/t95zdh7s6q1728bs885tygr0f794qx/T/ipykernel_31947/481864388.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Gene-Paralog'] = filtered_data['Gene'] + \"-\" + filtered_data['Paralog']\n"
     ]
    }
   ],
   "source": [
    "### checking dataframe for matching values in paper, Total CRISPR gene targets showing paralog upregulation = 16 (out of 73), Total upregulated paralogs = 57\n",
    "\n",
    "# excluding secondary conditions not used in main analysis of Mellis et al. 2023\n",
    "alt_sets = ['GSE92872-2', 'GSE145653-2', 'GSE161466-2', 'GSE161466-3', 'GSE161466-4', 'GSE175787-3', 'GSE175787-4', 'GSE175787-5', 'GSE175787-6']\n",
    "mask = ~allData['dataset'].isin(alt_sets)\n",
    "mainData = allData[mask]\n",
    "\n",
    "combined_file_path = os.path.join(outputDir, 'mainData.csv')\n",
    "#mainData.to_csv(combined_file_path, index=False)\n",
    "\n",
    "print(\"Total number of unique CRISPR gene targets: \", mainData['Gene'].nunique())\n",
    "print(\"Unique CRISPR gene targets: \", np.unique(mainData['Gene']))\n",
    "\n",
    "# Filter rows according to cutoffs in Mellis et al. 2023\n",
    "filtered_data = mainData[(mainData['pctUpreg_p_value'] < 0.1) & (mainData['padj'] < 0.05) & (mainData['FC2'] > 0.5)]\n",
    "\n",
    "# Checking the number of unique genes\n",
    "num_unique_genes_p = filtered_data['Gene'].nunique()\n",
    "print(np.unique(filtered_data['Gene']))\n",
    "print(\"Number of unique genes passing DESeq2 Filters: \", num_unique_genes_p)\n",
    "\n",
    "# Checking the number of unique 'Gene-Paralog' pairs\n",
    "filtered_data['Gene-Paralog'] = filtered_data['Gene'] + \"-\" + filtered_data['Paralog']\n",
    "num_unique_pairs = filtered_data['Gene-Paralog'].nunique()\n",
    "print(\"Number of unique 'Gene-Paralog' pairs: \", num_unique_pairs)\n",
    "\n",
    "\n",
    "combined_file_path = os.path.join(outputDir, 'filteredData.csv')\n",
    "#filtered_data.to_csv(combined_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
